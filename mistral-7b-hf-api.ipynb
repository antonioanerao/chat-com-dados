{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd8fdd7-e0ff-4b98-b919-cd22b6bc1923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:55.509277Z",
     "iopub.status.busy": "2024-02-24T11:29:55.509178Z",
     "iopub.status.idle": "2024-02-24T11:29:56.723535Z",
     "shell.execute_reply": "2024-02-24T11:29:56.723101Z",
     "shell.execute_reply.started": "2024-02-24T11:29:55.509266Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d14191b-393f-43bb-9e5f-37a0240bc493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:56.724265Z",
     "iopub.status.busy": "2024-02-24T11:29:56.724051Z",
     "iopub.status.idle": "2024-02-24T11:29:56.728547Z",
     "shell.execute_reply": "2024-02-24T11:29:56.728132Z",
     "shell.execute_reply.started": "2024-02-24T11:29:56.724228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir=\"cache_dir\"\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167eb948-647b-4c49-9fe1-6a8f2845b024",
   "metadata": {},
   "source": [
    "#### Leitura do arquivo e criação do splitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1cafe3-f4a4-4ef0-8ed9-ac39e3accd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:56.729279Z",
     "iopub.status.busy": "2024-02-24T11:29:56.729115Z",
     "iopub.status.idle": "2024-02-24T11:29:56.745560Z",
     "shell.execute_reply": "2024-02-24T11:29:56.745278Z",
     "shell.execute_reply.started": "2024-02-24T11:29:56.729262Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('docs/nat.txt') as f:\n",
    "    clt = f.read()\n",
    "\n",
    "# Criação de um objeto RecursiveCharacterTextSplitter para dividir o texto em pedaços\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad2f45e-6475-4e0b-8ad9-7b7fb0a9d8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:56.746058Z",
     "iopub.status.busy": "2024-02-24T11:29:56.745921Z",
     "iopub.status.idle": "2024-02-24T11:29:56.755061Z",
     "shell.execute_reply": "2024-02-24T11:29:56.754783Z",
     "shell.execute_reply.started": "2024-02-24T11:29:56.746047Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents([clt])\n",
    "text_chunks = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53798a5-5317-4fbc-ae1b-e06eca25e039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:56.755572Z",
     "iopub.status.busy": "2024-02-24T11:29:56.755448Z",
     "iopub.status.idle": "2024-02-24T11:29:57.533967Z",
     "shell.execute_reply": "2024-02-24T11:29:57.533602Z",
     "shell.execute_reply.started": "2024-02-24T11:29:56.755562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicialize o modelo de embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Isso retornará uma lista de vetores\n",
    "embeddings = model.encode(text_chunks, convert_to_tensor=False)  \n",
    "\n",
    "# Adiciona zeros para estender cada vetor até a dimensão 1536\n",
    "extended_embeddings = np.array([np.pad(emb, (0, 1536 - len(emb)), 'constant') for emb in embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1356940-9eb5-44fb-8ad0-e8ad77f1db06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:57.535089Z",
     "iopub.status.busy": "2024-02-24T11:29:57.534969Z",
     "iopub.status.idle": "2024-02-24T11:29:57.912143Z",
     "shell.execute_reply": "2024-02-24T11:29:57.911702Z",
     "shell.execute_reply.started": "2024-02-24T11:29:57.535078Z"
    }
   },
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "indexes = pc.list_indexes()\n",
    "index_name = 'natgpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24984a1b-802a-4b6a-9503-754eb0d1c75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:29:57.912714Z",
     "iopub.status.busy": "2024-02-24T11:29:57.912609Z",
     "iopub.status.idle": "2024-02-24T11:30:10.049146Z",
     "shell.execute_reply": "2024-02-24T11:30:10.048743Z",
     "shell.execute_reply.started": "2024-02-24T11:29:57.912704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index encontrada e apagada: natgpt\n",
      "Index natgpt criado\n"
     ]
    }
   ],
   "source": [
    "for i in indexes:\n",
    "    pc.delete_index(i['name'])\n",
    "    print('Index encontrada e apagada: ' + i['name'])\n",
    "\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(index_name, dimension=1536, metric='cosine', spec=PodSpec(environment=os.environ.get('PINECONE_ENV')))\n",
    "    print('Index '+index_name+' criado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c997369-fac0-4109-bbd6-560b3f81394d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:10.049824Z",
     "iopub.status.busy": "2024-02-24T11:30:10.049598Z",
     "iopub.status.idle": "2024-02-24T11:30:10.297320Z",
     "shell.execute_reply": "2024-02-24T11:30:10.296719Z",
     "shell.execute_reply.started": "2024-02-24T11:30:10.049814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Conecta na index criada\n",
    "pc_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "123deabf-4206-4bdc-aa29-eb884a6e3a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:10.297984Z",
     "iopub.status.busy": "2024-02-24T11:30:10.297878Z",
     "iopub.status.idle": "2024-02-24T11:30:10.300622Z",
     "shell.execute_reply": "2024-02-24T11:30:10.300292Z",
     "shell.execute_reply.started": "2024-02-24T11:30:10.297974Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents_to_insert = []\n",
    "for i, embedding in enumerate(extended_embeddings):\n",
    "    doc_id = f\"{i}\"\n",
    "    documents_to_insert.append({\"id\": doc_id, \"values\": embedding.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147f56bc-ca9e-4bdd-8270-3f9e275c22cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:10.301136Z",
     "iopub.status.busy": "2024-02-24T11:30:10.301018Z",
     "iopub.status.idle": "2024-02-24T11:30:31.053255Z",
     "shell.execute_reply": "2024-02-24T11:30:31.052658Z",
     "shell.execute_reply.started": "2024-02-24T11:30:10.301127Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insere os documentos na index do Pinecone\n",
    "pc_index.upsert(vectors=documents_to_insert)\n",
    "\n",
    "# Aguarda 20 segundos para dar tempo de atualizar a Index no Pinecone\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37e5b5-e7a1-419c-9ddf-b10e90225304",
   "metadata": {},
   "source": [
    "### Busca por similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1c3699-498d-4a3f-a203-b4e834ae6029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:31.053821Z",
     "iopub.status.busy": "2024-02-24T11:30:31.053722Z",
     "iopub.status.idle": "2024-02-24T11:30:31.056270Z",
     "shell.execute_reply": "2024-02-24T11:30:31.055860Z",
     "shell.execute_reply.started": "2024-02-24T11:30:31.053811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicialização do modelo para perguntas e respostas\n",
    "llm = InferenceClient(model=\"mistralai/Mistral-7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01c9c4a-e705-413f-a2ab-da28fff8f6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:31.056742Z",
     "iopub.status.busy": "2024-02-24T11:30:31.056650Z",
     "iopub.status.idle": "2024-02-24T11:30:31.073921Z",
     "shell.execute_reply": "2024-02-24T11:30:31.073566Z",
     "shell.execute_reply.started": "2024-02-24T11:30:31.056731Z"
    }
   },
   "outputs": [],
   "source": [
    "def perguntar(prompt, top_k=3, debug=False):\n",
    "    \"\"\"\n",
    "    Recebe um prompt do usuário para fazer uma busca semântica, encontra os resultados\n",
    "    correspondentes no documento original e passa o resultado como contexto ao LLM\n",
    "\n",
    "    Parâmetros:\n",
    "    - prompt (str): Prompt do usuário. Também é usado para a busca semântica\n",
    "    - top_k (int): Quantidade de resultados mais semalhantes\n",
    "    - debug (bool): Retorna (ou não) o contexto passado ao LLM\n",
    "\n",
    "    Retorna:\n",
    "    - Tipo do retorno: A resposta do LLM com base na pergunta e contexto\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gerando o vetor de consulta\n",
    "    query_vector = model.encode(prompt, convert_to_tensor=False)\n",
    "    \n",
    "    # Adiciona zeros para estender cada vetor até a dimensão 1536\n",
    "    padding_length = 1536 - len(query_vector)\n",
    "    padded_vector = np.pad(query_vector, (0, padding_length), 'constant')\n",
    "    \n",
    "    query_vector_list = padded_vector.tolist()\n",
    "    query_result = pc_index.query(vector=query_vector_list, top_k=top_k)\n",
    "    \n",
    "    contexto = []\n",
    "    for index, match in enumerate(query_result.matches):\n",
    "        contexto.append(text_chunks[int(match.id)])\n",
    "\n",
    "    input_text = f\"[INST]Responda em Português do Brasil exatamente o que foi perguntado. Não invente nenhuma informação: {prompt}.\\n\\nContexto: {contexto}[/INST]\"\n",
    "\n",
    "    response = llm.text_generation(\n",
    "        input_text,\n",
    "        temperature=0.2, \n",
    "        max_new_tokens=500,\n",
    "        top_k=30,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0\n",
    "    )\n",
    "\n",
    "    if(debug == True):\n",
    "        response = response + \"\\n\\n\\nDebug\\n---------------------------------\\n\" + str(contexto)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7e97a-8ac0-4d62-8dea-de29c57c184f",
   "metadata": {},
   "source": [
    "### Perguntas com base no contexto passado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e38e3c8-74b0-4440-ba33-beab2697bc56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:31.074417Z",
     "iopub.status.busy": "2024-02-24T11:30:31.074296Z",
     "iopub.status.idle": "2024-02-24T11:30:32.321307Z",
     "shell.execute_reply": "2024-02-24T11:30:32.320967Z",
     "shell.execute_reply.started": "2024-02-24T11:30:31.074408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Os coordenadores do NAT são Marcela Cristina Ozório e Bernardo Fiterman Albano.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Quem são os coordenadores do nat?', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ab25ff-2b9b-40b2-ba2b-73d64454542d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:32.321886Z",
     "iopub.status.busy": "2024-02-24T11:30:32.321717Z",
     "iopub.status.idle": "2024-02-24T11:30:32.825962Z",
     "shell.execute_reply": "2024-02-24T11:30:32.825617Z",
     "shell.execute_reply.started": "2024-02-24T11:30:32.321874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O site do NAT é: <https://nat.mpac.mp.br>.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Qual o site do nat?', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "515f32f1-77c9-4805-a20f-12e3fae5866b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:32.826467Z",
     "iopub.status.busy": "2024-02-24T11:30:32.826343Z",
     "iopub.status.idle": "2024-02-24T11:30:33.304204Z",
     "shell.execute_reply": "2024-02-24T11:30:33.303862Z",
     "shell.execute_reply.started": "2024-02-24T11:30:32.826455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O NAT (Núcleo de Apoio Técnico) é um órgão administrativo auxiliar de apoio técnico especializado do Ministério Público do Estado do Acre. Os principais setores do NAT são: Coordenação de Desenvolvimento de Sistemas, Observatório Criminal, LAB (Laboratório de Tecnologia contra a Lavagem de Dinheiro), Observatório de Políticas Públicas e Técinco Científico.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Quais os principais setores do NAT?', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c8770d-0b10-46f6-9a89-229c4a651293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:33.304762Z",
     "iopub.status.busy": "2024-02-24T11:30:33.304633Z",
     "iopub.status.idle": "2024-02-24T11:30:33.780372Z",
     "shell.execute_reply": "2024-02-24T11:30:33.780052Z",
     "shell.execute_reply.started": "2024-02-24T11:30:33.304750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O NAT (Núcleo de Apoio Técnico) é um órgão do MPAC (Ministério Público do Acre) criado em 2012. Ele tem como função atender a demandas de processos complexos e intersetoriais, onde todos os setores atuam de forma integrada. O NAT tem como principais setores a Coordenação de Desenvolvimento de Sistemas, Observatório Criminal, LAB (Laboratório de Tecnologia contra a Lavagem de Dinheiro), Observatório de Políticas Públicas e Técinco Científico. O site do NAT é https://nat.mpac.mp.br.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Me da um resumo do NAT?', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38aed8bd-9ce4-4397-8acd-4872226fbb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:33.780932Z",
     "iopub.status.busy": "2024-02-24T11:30:33.780789Z",
     "iopub.status.idle": "2024-02-24T11:30:34.256323Z",
     "shell.execute_reply": "2024-02-24T11:30:34.255689Z",
     "shell.execute_reply.started": "2024-02-24T11:30:33.780920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O Observatório de Políticas Públicas (OPP) é um projeto do Núcleo de Apoio Técnico (NAT), órgão do MPAC (Ministério Público do Acre), criado em 2012. O OPP tem como objetivo monitorar os orçamentos públicos e a aplicação dos recursos, verificando a consonância entre o que foi planejado com o executado e se o resultado almejado foi alcançado e promoveu a transformação social que era buscada. O OPP usará instrumentos formais, como o Plano Plurianual, Lei de Diretrizes Orçamentárias e Lei Orçamentária Anual, para produzir e disponibilizar dados, informações e conhecimentos aos membros do MPAC. O OPP abrangerá as áreas da saúde, educação, meio ambiente, segurança pública e políticas de assistência social.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Me da um resumo do Observatório de Políticas Públicas', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6e3fcc8-7cf7-47f7-b3a3-a4543ba2abfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:34.256872Z",
     "iopub.status.busy": "2024-02-24T11:30:34.256769Z",
     "iopub.status.idle": "2024-02-24T11:30:34.732607Z",
     "shell.execute_reply": "2024-02-24T11:30:34.732248Z",
     "shell.execute_reply.started": "2024-02-24T11:30:34.256860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O site do OPP (Observatório De Políticas Públicas) é: <https://nat.mpac.mp.br/posts/category/observatorio-politicas-publicas/>.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Qual o site do OPP', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ebaacb7-bea3-4682-8204-9363153bbc22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:34.733116Z",
     "iopub.status.busy": "2024-02-24T11:30:34.733004Z",
     "iopub.status.idle": "2024-02-24T11:30:35.209921Z",
     "shell.execute_reply": "2024-02-24T11:30:35.209517Z",
     "shell.execute_reply.started": "2024-02-24T11:30:34.733106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O Retina é uma ferramenta gerenciadora de conteúdo, desenvolvida a partir do armazenamento de dados/informações relacionados às organizações criminosas e a seus integrantes. A ferramenta possibilita aos usuários (observadores) o cadastro de fatos formais relacionados a atuaação de facções/ORCRIM e a posterior consulta por meio de filtros relacionados aos integrantes (observados), assim como a geração de análises de correlação e de vínculo entre pessoas, entre fatos e entre pessoas e fatos.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='O que é o Retina?', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5af0222f-19fa-4daf-8eca-9b9056e95bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T11:30:35.210401Z",
     "iopub.status.busy": "2024-02-24T11:30:35.210298Z",
     "iopub.status.idle": "2024-02-24T11:30:35.700253Z",
     "shell.execute_reply": "2024-02-24T11:30:35.699891Z",
     "shell.execute_reply.started": "2024-02-24T11:30:35.210391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Redes neurais artificiais são sistemas computacionais que são inspirados no funcionamento do cérebro humano. São compostos por uma grande quantidade de neurônios que são interconectados por meio de sinapses, e que trabalham juntos para processar e analisar informação. Redes neurais artificiais são utilizadas em diversos campos, como a inteligência artificial, o reconhecimento de padrões, a previsão de comportamento e a resolução de problemas.\n"
     ]
    }
   ],
   "source": [
    "# Pergunta com resposta totalmente fora do contexto\n",
    "print(\n",
    "    perguntar(\n",
    "        prompt='O que são redes neurais artificiais', top_k=4, debug=False\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
